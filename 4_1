import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder

# Activation
def sigmoid(x): return 1 / (1 + np.exp(-x))
def sigmoid_deriv(x): return x * (1 - x)

# Load and prepare data
X, y = load_iris(return_X_y=True)
X = StandardScaler().fit_transform(X)
y = OneHotEncoder(sparse_output=False).fit_transform(y.reshape(-1, 1))
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize weights and biases
np.random.seed(1)
w1, w2 = np.random.rand(4, 5), np.random.rand(5, 3)
b1, b2 = np.zeros((1, 5)), np.zeros((1, 3))

# Training
for epoch in range(500):
    h = sigmoid(X_train @ w1 + b1)
    out = sigmoid(h @ w2 + b2)
    loss = np.mean((y_train - out) ** 2)
    if epoch % 100 == 0:
        print(f"Epoch {epoch}, Loss: {loss:.4f}")
    d_out = (y_train - out) * sigmoid_deriv(out)
    d_h = (d_out @ w2.T) * sigmoid_deriv(h)
    w2 += 0.01 * h.T @ d_out
    b2 += 0.01 * np.sum(d_out, axis=0, keepdims=True)
    w1 += 0.01 * X_train.T @ d_h
    b1 += 0.01 * np.sum(d_h, axis=0, keepdims=True)

# Testing (fixed)
h_test = sigmoid(X_test @ w1 + b1)
out_test = sigmoid(h_test @ w2 + b2)
acc = np.mean(np.argmax(out_test, axis=1) == np.argmax(y_test, axis=1)) * 100
print(f"Test Accuracy: {acc:.2f}%")
